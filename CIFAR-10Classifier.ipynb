{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMkmbz_bsCh-"
   },
   "source": [
    "# Classificador de imágenes (Cifar-10 Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxxbU0zJr85A"
   },
   "source": [
    "## Librerías y clases necesarías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvZQ0BBTZtaN"
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7CKCDBALm74"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Parada temprara del entrenamiento si el coste de validación no mejora tras {patience} iteraciones\"\"\"\n",
    "    def __init__(self, ident, path, patience=7, verbose=True, delta=0):\n",
    "\n",
    "        self.ident = ident\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.stop_iter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model, i):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            #print(f'EarlyStopping counter: {self.counter} de {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "              if not self.early_stop:\n",
    "                self.early_stop = True\n",
    "                self.stop_iter = i - self.patience\n",
    "                if self.verbose:\n",
    "                  print(f'Mejora estancada por {self.patience} épocas ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Activando early stop ...')\n",
    "                \n",
    "        else:\n",
    "          self.save_checkpoint(val_loss, model)\n",
    "          self.best_score = score\n",
    "          self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Guarda el valor de los parámetros en checkpoint'''\n",
    "        torch.save(model.state_dict(), os.path.join(data_path, f'checkpoint-{self.ident}.pt'))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Tc9QB1eX7cw"
   },
   "source": [
    "### Conectar google colab a sistema de archivos en la nube (Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCw_4TPTWf1B"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMtF-dILKbuk"
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),'gdrive', 'My Drive','Colab Notebooks', 'data', 'cifar-10')\n",
    "log_path = os.path.join(os.getcwd(),'gdrive', 'My Drive','Colab Notebooks', 'logs', 'cifar-10')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "tensorboard_path = f\"'{log_path}'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyMmUO2LisD_"
   },
   "source": [
    "## Cargar TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRbl8dbryBC6"
   },
   "source": [
    "### Utilizar ngrok para ver tensorboard en un navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWsnbMoJBTFT"
   },
   "outputs": [],
   "source": [
    "!pkill tensorboard\n",
    "!pkill ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zttffFkyJAvD"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZscQHqvKT5G"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $tensorboard_path --host localhost --port 6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCoq2i9Xycz-"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6007 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVQZwhe8yiHg"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJJAPh_Ksovn"
   },
   "source": [
    "## Preparando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukACPzS4r4zp"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "\n",
    "batch_size_train = 25\n",
    "\n",
    "learning_rate = 0.0005\n",
    "sgd_learning_rate= 0.001\n",
    "\n",
    "momentum = 0.9\n",
    "log_interval = 50\n",
    "batch_test_interval = 30\n",
    "patience_value = 3\n",
    "\n",
    "validation_set_size = 10000\n",
    "\n",
    "# Fijando la semilla siempre nos dara los mismo resultados cada vez que lo corramos\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aE5BKWSsZu6"
   },
   "source": [
    "### Datos de entrenamiento y testeo\n",
    "\n",
    "#### Manejo de los DataLoaders\n",
    "> [Enlace a la documentación](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m77T30SjoDnw"
   },
   "outputs": [],
   "source": [
    "data_set =   torchvision.datasets.CIFAR10(data_path, train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()]))\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(data_path, train=False, download = True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()]))\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(data_set, [len(data_set) - validation_set_size , validation_set_size])\n",
    "validation_loader = torch.utils.data.DataLoader(val_set, batch_size=validation_set_size, shuffle=False)\n",
    "no_batch_train_loader = torch.utils.data.DataLoader(train_set,batch_size= len(data_set) - validation_set_size, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size_train, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=len(test_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNI_AkOd8mJB"
   },
   "source": [
    "### Cargar imágenes en tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmHlOvd2ibiB"
   },
   "outputs": [],
   "source": [
    "SGD_wr = SummaryWriter(os.path.join(log_path, 'images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTv28wcG8qr6"
   },
   "outputs": [],
   "source": [
    "def load_images(wr, loader, set_name):\n",
    "  print(f\"Saving {set_name}...\")\n",
    "  for idx, (images, labels) in enumerate(loader):\n",
    "    batch_grid = torchvision.utils.make_grid(images)\n",
    "    wr.add_image(f\"{set_name}/Lote-{idx}\", batch_grid)\n",
    "  print(f\"{set_name} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHYTnDGKOkYF"
   },
   "outputs": [],
   "source": [
    "load_images(SGD_wr, train_loader, 'Training data')\n",
    "load_images(SGD_wr, test_loader, 'Test data')\n",
    "load_images(SGD_wr, validation_loader, 'Validation data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OjbFGsjVY14"
   },
   "source": [
    "### Muestra de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgR2AGN-r8aw"
   },
   "outputs": [],
   "source": [
    "test_examples = enumerate(test_loader)\n",
    "test_batch_idx, (example_test_data, example_test_targets) = next(test_examples)\n",
    "\n",
    "train_examples = enumerate(train_loader)\n",
    "train_batch_idx, (example_train_data, example_train_targets) = next(train_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiGztEvU3nin"
   },
   "outputs": [],
   "source": [
    "example_train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elDyQzg23LHO"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.imshow(example_train_data[2][2], cmap='Reds')\n",
    "#plt.title(\"Representación: {}\".format(example_train_targets[i]), {'fontsize':15})\n",
    "plt.xticks([])\n",
    "plt.yticks([]) \n",
    "fig.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvY3ptheqVEu"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxydQjBuETd-"
   },
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(example_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIBBaUmAVdJm"
   },
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dx0EMs1SL2xe"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de un batch del conjunto de datos de test es {example_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETmocy_imWOQ"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de un batch del conjunto de datos de entrenamiento es {example_train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8n3hJxPm3Cx"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de los conjuntos:\\nEntrenamiento: {len(data_set) - validation_set_size}\\nValidación: {validation_set_size}\\nTest: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGxLLHXr0nxZ"
   },
   "source": [
    "## Construyendo la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWRFeoKOuKx2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUL2YQ7ay1O4"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = name\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__Zjzxa9l1rB"
   },
   "source": [
    "### Creación de modelos a comparar fijación de criterios de optimización\n",
    "> Optimización --> \n",
    "- Gradiente descendiente estocástico por lotes\n",
    "- Gradiente descendente estocástico por lotes con momento\n",
    "- ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okZ4fSsr0uZ2"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "SGD_modelo = Net(\"Modelo con gradiente descendente estocástico\")\n",
    "SGD_optimizer = optim.SGD(SGD_modelo.parameters(), lr=sgd_learning_rate)\n",
    "SGD_early_stopper = EarlyStopping('SGD', data_path, patience=patience_value)\n",
    "SGD_wr = SummaryWriter(os.path.join(log_path,'SGD'))\n",
    "SGD_val_wr = SummaryWriter(os.path.join(log_path,'SGD_val'))\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "SGDM_modelo = Net(\"Modelo con gradiente descendente estocástico con momento\")\n",
    "SGDM_optimizer = optim.SGD(SGDM_modelo.parameters(), lr=learning_rate, momentum=momentum)\n",
    "SGDM_early_stopper = EarlyStopping('SGD', data_path, patience=patience_value)\n",
    "SGDM_wr = SummaryWriter(os.path.join(log_path,'SGDM'))\n",
    "SGDM_val_wr = SummaryWriter(os.path.join(log_path,'SGDM_val'))\n",
    "\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "ADAM_modelo = Net(\"Modelo con ADAM\")\n",
    "ADAM_optimizer = optim.Adam(ADAM_modelo.parameters(), lr=learning_rate, betas= (momentum, 0.99))\n",
    "ADAM_early_stopper = EarlyStopping('ADAM', data_path, patience=patience_value)\n",
    "ADAM_wr = SummaryWriter(os.path.join(log_path,'ADAM'))\n",
    "ADAM_val_wr = SummaryWriter(os.path.join(log_path,'ADAM_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su1l99waHZ88"
   },
   "outputs": [],
   "source": [
    "p = sum(p.numel() for p in SGD_modelo.parameters() if p.requires_grad)\n",
    "print(f'El número de parámetros entrenables es: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4jBlKw50u97"
   },
   "source": [
    "## Entrenando la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZHoc3iBmNvL"
   },
   "source": [
    "Función de coste\n",
    "> $Cross\\_entropy = nll\\_loss(log\\_softmax(x))$\n",
    "\n",
    " [Negative log likelihood loss (nll)](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
    "\n",
    "* Función de activación Softmax --> comúnmente utilizada para problemas  de aprendizaje multiclase donde un conjunto de características puede asociaser a 1 de K clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hkFAyJGwVp6"
   },
   "outputs": [],
   "source": [
    "def train(epoch, modelo, optimizer, wr:SummaryWriter):\n",
    "\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "    modelo.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = modelo(data)\n",
    "    loss = F.nll_loss(output, target, reduction='mean')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    wr.add_scalar('Loss/train', loss.item(), batch_idx + (epoch - 1) * len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAs37pdXRmEi"
   },
   "outputs": [],
   "source": [
    "def train_error(epoch, modelo, wr):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  train_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in no_batch_train_loader:\n",
    "      output = modelo(data)\n",
    "      train_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "    wr.add_scalar('Loss/early', train_loss, epoch)\n",
    "  print(f'\\nTrain set: Avg. loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocMvJRlKcwYI"
   },
   "outputs": [],
   "source": [
    "def validation(epoch, modelo, wr, es):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  validation_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in validation_loader:\n",
    "      output = modelo(data)\n",
    "      validation_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    es(validation_loss, modelo, epoch)\n",
    "    wr.add_scalar('Loss/early', validation_loss, epoch)\n",
    "    wr.add_scalar('Accuracy/validation', 100. * correct / len(validation_loader.dataset), epoch)\n",
    "  print(f'\\nValidation set: Avg. loss: {validation_loss:.4f}, Accuracy: {correct}/{len(validation_loader.dataset)} ({100. * correct / len(validation_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-JU2l7wwjvY"
   },
   "outputs": [],
   "source": [
    "def test(epoch, modelo, wr):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  test_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = modelo(data)\n",
    "      # Reduction mean --> Calcula la función de coste por cada ejemplo y hace la media \n",
    "      test_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "      # pred --> Devuelve el index del valor maximo (predicción)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    wr.add_scalar('Loss/test', test_loss, epoch)\n",
    "    wr.add_scalar('Accuracy/test', 100. * correct / len(test_loader.dataset), epoch)\n",
    "  print(f'\\nTest set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYpPfKwV3-1P"
   },
   "source": [
    "### Rutina de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c52DBddCQgMi"
   },
   "outputs": [],
   "source": [
    "print(\"Training with SGD\\n***************** Sin entrenamiento *********************\")\n",
    "train_error(0, SGD_modelo, SGD_wr)\n",
    "validation(0, SGD_modelo, SGD_val_wr, SGD_early_stopper)\n",
    "test(0, SGD_modelo, SGD_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, SGD_modelo, SGD_optimizer, SGD_wr)\n",
    "\n",
    "  train_error(epoch, SGD_modelo, SGD_wr)\n",
    "  validation(epoch, SGD_modelo, SGD_val_wr, SGD_early_stopper)\n",
    "  test(epoch, SGD_modelo, SGD_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNilbdMpt-xR"
   },
   "outputs": [],
   "source": [
    "print(\"Training with SGD with momentum\\n***************** Sin entrenamiento *********************\")\n",
    "train_error(0, SGDM_modelo, SGDM_wr)\n",
    "validation(0, SGDM_modelo, SGDM_val_wr, SGDM_early_stopper)\n",
    "test(0, SGDM_modelo, SGDM_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, SGDM_modelo, SGDM_optimizer, SGDM_wr)\n",
    "\n",
    "  train_error(epoch, SGDM_modelo, SGDM_wr)\n",
    "  validation(epoch, SGDM_modelo, SGDM_val_wr, SGDM_early_stopper)\n",
    "  test(epoch, SGDM_modelo, SGDM_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GP9Z7gOl36aV"
   },
   "outputs": [],
   "source": [
    "print(\"Training with ADAM\\n***************** Sin entrenamiento *********************\")\n",
    "train_error(0, ADAM_modelo, ADAM_wr)\n",
    "validation(0, ADAM_modelo, ADAM_val_wr, ADAM_early_stopper)\n",
    "test(0, ADAM_modelo, ADAM_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, ADAM_modelo, ADAM_optimizer, ADAM_wr)\n",
    "\n",
    "  train_error(epoch, ADAM_modelo, ADAM_wr)\n",
    "  validation(epoch, ADAM_modelo, ADAM_val_wr, ADAM_early_stopper)\n",
    "  test(epoch, ADAM_modelo, ADAM_wr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6s1keMx04GV"
   },
   "source": [
    "## Evaluando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5SloJ7Jx7qb"
   },
   "outputs": [],
   "source": [
    "if (SGD_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de SGD con un coste de {SGD_early_stopper.val_loss_min}\\nÉpoca número:{SGD_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en SGD, siendo el menor coste: {SGD_early_stopper.val_loss_min}\\n\")\n",
    "\n",
    "if (SGDM_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de SGD con momento con coste de {SGDM_early_stopper.val_loss_min}\\nÉpoca número:{SGDM_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en SGD con momento, siendo el menor coste: {SGDM_early_stopper.val_loss_min}\\n\")\n",
    "\n",
    "if (ADAM_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de ADAM con coste de {ADAM_early_stopper.val_loss_min}\\nÉpoca número:{ADAM_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en ADAM, siendo el menor coste: {ADAM_early_stopper.val_loss_min}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Álvaro Rubio Segovia\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CIFARClassifier_v2.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}