{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMkmbz_bsCh-"
   },
   "source": [
    "# Classificador de imágenes (MINST Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxxbU0zJr85A"
   },
   "source": [
    "## Librerías y clases necesarías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvZQ0BBTZtaN"
   },
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcT9jlLutlCr"
   },
   "source": [
    "### Clases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7CKCDBALm74"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Parada temprara del entrenamiento si el coste de validación no mejora tras {patience} iteraciones\"\"\"\n",
    "    def __init__(self, ident, path, patience=7, verbose=True, delta=0):\n",
    "\n",
    "        self.ident = ident\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.stop_iter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model, i):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            #print(f'EarlyStopping counter: {self.counter} de {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "              if not self.early_stop:\n",
    "                self.early_stop = True\n",
    "                self.stop_iter = i - self.patience\n",
    "                if self.verbose:\n",
    "                  print(f'[{i}] Mejora estancada por {self.patience} iteraciones ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Activando early stop ...')\n",
    "              \n",
    "        else:\n",
    "          self.save_checkpoint(val_loss, model)\n",
    "          self.best_score = score\n",
    "          self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Guarda el valor de los parámetros en checkpoint'''\n",
    "        torch.save(model.state_dict(), os.path.join(self.path, f'checkpoint-{self.ident}.pt'))\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Tc9QB1eX7cw"
   },
   "source": [
    "### Conectar google colab a sistema de archivos en la nube (Google Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCw_4TPTWf1B"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMtF-dILKbuk"
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),'gdrive', 'My Drive','Colab Notebooks', 'data', 'mnist')\n",
    "log_path = os.path.join(os.getcwd(),'gdrive', 'My Drive','Colab Notebooks', 'logs', 'minst')\n",
    "os.makedirs(data_path, exist_ok=True, )\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "tensorboard_path = f\"'{log_path}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyMmUO2LisD_"
   },
   "source": [
    "## Cargar TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWsnbMoJBTFT"
   },
   "outputs": [],
   "source": [
    "!pkill tensorboard\n",
    "!pkill ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zttffFkyJAvD"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZscQHqvKT5G"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $tensorboard_path --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRbl8dbryBC6"
   },
   "source": [
    "### Utilizar ngrok para ver tensorboard en un navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCoq2i9Xycz-"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IB7McDEWM_nW"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVQZwhe8yiHg"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJJAPh_Ksovn"
   },
   "source": [
    "## Preparando el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukACPzS4r4zp"
   },
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "# Fijando la semilla siempre nos dara los mismo resultados cada vez que lo corramos\n",
    "random_seed = 1\n",
    "\n",
    "batch_size_train = 64\n",
    "validation_set_size = 10000\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "momentum = 0.9\n",
    "log_interval = 10\n",
    "patience_value = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HzQv8x0x5mM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aE5BKWSsZu6"
   },
   "source": [
    "### Datos de entrenamiento y testeo\n",
    "\n",
    "#### Manejo de los DataLoaders\n",
    "> [Enlace a la documentación](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m77T30SjoDnw"
   },
   "outputs": [],
   "source": [
    "data_set =   torchvision.datasets.MNIST(data_path, train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                               # , torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(data_path, train=False, download = True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                              # , torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(data_set, [len(data_set) - validation_set_size , validation_set_size])\n",
    "validation_loader = torch.utils.data.DataLoader(val_set, batch_size = validation_set_size, shuffle=False)\n",
    "no_batch_train_loader = torch.utils.data.DataLoader(train_set, batch_size=len(data_set)-validation_set_size, shuffle=False)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size_train, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size = len(data_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNI_AkOd8mJB"
   },
   "source": [
    "### Cargar imágenes en tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmHlOvd2ibiB"
   },
   "outputs": [],
   "source": [
    "SGD_wr = SummaryWriter(os.path.join(log_path, 'images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTv28wcG8qr6"
   },
   "outputs": [],
   "source": [
    "def load_images(wr, loader, set_name):\n",
    "  print(f\"Saving {set_name}...\")\n",
    "  for idx, (images, labels) in enumerate(loader):\n",
    "    batch_grid = torchvision.utils.make_grid(images)\n",
    "    wr.add_image(f\"{set_name}/Lote-{idx}\", batch_grid)\n",
    "  print(f\"{set_name} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHYTnDGKOkYF"
   },
   "outputs": [],
   "source": [
    "load_images(SGD_wr, train_loader, 'Training data')\n",
    "load_images(SGD_wr, test_loader, 'Test data')\n",
    "load_images(SGD_wr, validation_loader, 'Validation data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OjbFGsjVY14"
   },
   "source": [
    "### Muestra de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgR2AGN-r8aw"
   },
   "outputs": [],
   "source": [
    "test_examples = enumerate(test_loader)\n",
    "test_batch_idx, (example_test_data, example_test_targets) = next(test_examples)\n",
    "\n",
    "train_examples = enumerate(train_loader)\n",
    "train_batch_idx, (example_train_data, example_train_targets) = next(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dx0EMs1SL2xe"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de un batch del conjunto de datos de test es {example_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETmocy_imWOQ"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de un batch del conjunto de datos de test es {example_train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8n3hJxPm3Cx"
   },
   "outputs": [],
   "source": [
    "print(f\"Dimensión de los conjuntos:\\nEntrenamiento: {len(data_set) - validation_set_size }\\nValidación: {validation_set_size}\\nTest: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rs5rLj5RS-zk"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_train_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Representación: {}\".format(example_train_targets[i]), {'fontsize':15})\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "fig.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGxLLHXr0nxZ"
   },
   "source": [
    "## Construyendo la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWRFeoKOuKx2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUL2YQ7ay1O4"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super(Net, self).__init__()\n",
    "        self.name = name\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        \n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__Zjzxa9l1rB"
   },
   "source": [
    "### Creación de modelos a comparar fijación de criterios de optimización\n",
    "> Optimización --> \n",
    "- Gradiente descendente estocástico\n",
    "- Gradiente descendente estocastico con momento\n",
    "- ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okZ4fSsr0uZ2"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "SGD_modelo = Net(\"Modelo con gradiente descendente estocástico\")\n",
    "SGD_optimizer = optim.SGD(SGD_modelo.parameters(), lr=learning_rate)\n",
    "SGD_early_stopper = EarlyStopping('SGD', data_path, patience=patience_value)\n",
    "SGD_wr = SummaryWriter(os.path.join(log_path,'SGD'))\n",
    "SGD_val_wr = SummaryWriter(os.path.join(log_path,'SGD_val'))\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "SGDM_modelo = Net(\"Modelo con gradiente descendente estocástico con momento\")\n",
    "SGDM_optimizer = optim.SGD(SGDM_modelo.parameters(), lr=learning_rate, momentum=momentum)\n",
    "SGDM_early_stopper = EarlyStopping('SGD', data_path, patience=patience_value)\n",
    "SGDM_wr = SummaryWriter(os.path.join(log_path,'SGDM'))\n",
    "SGDM_val_wr = SummaryWriter(os.path.join(log_path,'SGDM_val')) \n",
    "\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "ADAM_modelo = Net(\"Modelo con ADAM\")\n",
    "ADAM_optimizer = optim.Adam(ADAM_modelo.parameters(), lr=learning_rate)\n",
    "ADAM_early_stopper = EarlyStopping('ADAM', data_path, patience=patience_value)\n",
    "ADAM_wr = SummaryWriter(os.path.join(log_path,'ADAM'))\n",
    "ADAM_val_wr = SummaryWriter(os.path.join(log_path,'ADAM_val'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crt7Az8M1Def"
   },
   "outputs": [],
   "source": [
    "p = sum(p.numel() for p in SGD_modelo.parameters() if p.requires_grad)\n",
    "print(f'El número de parámetros entrenables es: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZeK3j-8fw-o"
   },
   "source": [
    "## Transformación del input en el output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOPzoTQHQ9LG"
   },
   "outputs": [],
   "source": [
    "examples_train_data = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4xg1WX4WLZf"
   },
   "source": [
    "### Salida de bloque uno (Convolucional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfT_lpWIcMkz"
   },
   "source": [
    "#### Convolución\n",
    "\n",
    "*   Padding = 0\n",
    "*   Filters size = 5 x 5\n",
    "*   Number of features map per image = 10\n",
    "*   Size of the features map = 24 x 24\n",
    "\n",
    "En este caso el batch es igual a 64 por lo que existen 64 x 10 mapas de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8u9yV70hcMkq"
   },
   "outputs": [],
   "source": [
    "SGD_modelo.conv1(example_data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j05b91APcMko"
   },
   "source": [
    "#### Pooling\n",
    "\n",
    "* Kernel size = 2 x 2\n",
    "* Features map size = 12 x 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1cfZht7cMkg"
   },
   "outputs": [],
   "source": [
    "F.max_pool2d(SGD_modelo.conv1(example_data), 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDMlcUgKcMke"
   },
   "source": [
    "#### Función de activación --> ReLu\n",
    "\n",
    "Solo lo valores mayores que cero permanecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExN--GnwcMkS"
   },
   "outputs": [],
   "source": [
    "block_one_output = F.relu(F.max_pool2d(SGD_modelo.conv1(example_data), 2))\n",
    "print(\"La dimensión de cada mapa de características es {} \\n \".format(block_one_output[0][0].shape))\n",
    "block_one_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hi5JRJ6_cOnY"
   },
   "source": [
    "### Salida de bloque dos (Convolucional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJrL5YEKcR8p"
   },
   "source": [
    "#### Convolución\n",
    "\n",
    "*   Padding = 0\n",
    "*   Filters size = 5 x 5\n",
    "*   Number of features map per image = 20\n",
    "*   Size of the features map = 8 x 8 \n",
    "\n",
    "En este caso el batch es igual a 64 por lo que existen 64 x 20 mapas de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZSzYd9AcR8q"
   },
   "outputs": [],
   "source": [
    "SGD_modelo.conv2(block_one_output).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cwCTDQ-cR8t"
   },
   "source": [
    "#### Pooling\n",
    "\n",
    "* Kernel size = 2 x 2\n",
    "* Features map size = 4 x 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9xhjA83cR8u"
   },
   "outputs": [],
   "source": [
    "F.max_pool2d(SGD_modelo.conv2(block_one_output), 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEUpdFW8cR8w"
   },
   "source": [
    "#### Función de activación --> ReLu\n",
    "\n",
    "Solo lo valores mayores que cero permanecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQ_vknGOcR8x"
   },
   "outputs": [],
   "source": [
    "block_two_output = F.relu(F.max_pool2d(SGD_modelo.conv2(block_one_output), 2))\n",
    "print(\"La dimensión de cada mapa de características es {} \\n \".format(block_two_output[0][0].shape))\n",
    "block_two_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phn1o8c_Y2v2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRrh2D3HfMEk"
   },
   "source": [
    "### Salida de bloque tres\n",
    "\n",
    "Transforma los mapas de características en un vector de características\n",
    "\n",
    ">El argumento -1 indica que el número de imágenes en el batch se infiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzX0HAOofbPR"
   },
   "outputs": [],
   "source": [
    "block_three_output = block_two_output.view(-1, 20 * 4 * 4)\n",
    "block_three_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TN9qGTSqgy5r"
   },
   "source": [
    "### Salida del bloque cuatro\n",
    "Se opera como si fuera una Feed Forward Neural Network\n",
    "> Función de activación ReLu <br>\n",
    "> Reduce el vector de características de 320 a 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz-zLU4HhPme"
   },
   "outputs": [],
   "source": [
    "block_four_output = F.relu(SGD_modelo.fc1(block_three_output))\n",
    "block_four_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TkqFkChhyiT"
   },
   "source": [
    "### Salida del bloque cinco (Función Softmax)\n",
    "Se reduce de la salida de la última capa a un vector de 10 valores\n",
    "> Número de clases = 10 (rango 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "taJSA8dviSXf"
   },
   "outputs": [],
   "source": [
    "  block_five_output =  F.log_softmax(SGD_modelo.fc2(block_four_output), dim=1)\n",
    "  block_five_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4jBlKw50u97"
   },
   "source": [
    "## Entrenando la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZHoc3iBmNvL"
   },
   "source": [
    "Función de coste\n",
    "> $Cross\\_entropy = nll\\_loss(log\\_softmax(x))$\n",
    "\n",
    " [Negative log likelihood loss (nll)](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
    "\n",
    "* Función de activación Softmax --> comúnmente utilizada para problemas  de aprendizaje multiclase donde un conjunto de características puede asociaser a 1 de K clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0astXl9ZzECC"
   },
   "outputs": [],
   "source": [
    "def train(epoch, modelo, optimizer, wr:SummaryWriter):\n",
    "\n",
    "# train epoch\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "    modelo.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = modelo(data)\n",
    "    loss = F.nll_loss(output, target, reduction='mean')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    wr.add_scalar('Loss/train', loss.item(), batch_idx + (epoch - 1) * len(train_loader))\n",
    "    \n",
    "# end epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAs37pdXRmEi"
   },
   "outputs": [],
   "source": [
    "def train_error(epoch, modelo, wr):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  train_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in no_batch_train_loader:\n",
    "      output = modelo(data)\n",
    "      train_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "    wr.add_scalar('Loss/early', train_loss, epoch)\n",
    "  print(f'\\nTrain set: Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocMvJRlKcwYI"
   },
   "outputs": [],
   "source": [
    "def validation(epoch, modelo, wr, es):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  validation_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in validation_loader:\n",
    "      output = modelo(data)\n",
    "      validation_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    es(validation_loss, modelo, epoch)\n",
    "    wr.add_scalar('Loss/early', validation_loss, epoch)\n",
    "    wr.add_scalar('Accuracy/Validation', 100. * correct / len(validation_loader.dataset), epoch)\n",
    "  print(f'\\nValidation set: Avg. loss: {validation_loss:.4f}, Accuracy: {correct}/{len(validation_loader.dataset)} ({100. * correct / len(validation_loader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKhaKeaczXAo"
   },
   "outputs": [],
   "source": [
    "def test(epoch, modelo, wr):\n",
    "  modelo.eval()\n",
    "  correct = 0\n",
    "  test_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader: \n",
    "      output = modelo(data)\n",
    "      test_loss += F.nll_loss(output, target, reduction='mean').item()\n",
    "      # pred --> Devuelve el index del valor maximo (predicción)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    wr.add_scalar('Loss/test', test_loss, epoch)\n",
    "    wr.add_scalar('Accuracy/test', 100. * correct / len(test_loader.dataset), epoch)\n",
    "  print(f'\\nTest set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYpPfKwV3-1P"
   },
   "source": [
    "### Rutina de aprendizaje\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4NnBRDaz1zC"
   },
   "outputs": [],
   "source": [
    "print(\"Training with SGD\\n ***************** Sin entrenamiento *********************\")\n",
    "train_error(0, SGD_modelo, SGD_wr)\n",
    "validation(0, SGD_modelo, SGD_val_wr, SGD_early_stopper)\n",
    "test(0, SGD_modelo, SGD_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, SGD_modelo, SGD_optimizer, SGD_wr)\n",
    "  \n",
    "  train_error(epoch, SGD_modelo, SGD_wr)\n",
    "  validation(epoch, SGD_modelo, SGD_val_wr, SGD_early_stopper)\n",
    "  test(epoch, SGD_modelo, SGD_wr)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTP9Qoz0VrbA"
   },
   "outputs": [],
   "source": [
    "print(\"Training with SGDM\\n***************** Sin entrenamiento *********************\")\n",
    "train_error(0, SGDM_modelo, SGDM_wr)\n",
    "validation(0, SGDM_modelo, SGDM_val_wr, SGDM_early_stopper)\n",
    "test(0, SGDM_modelo, SGDM_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, SGDM_modelo, SGDM_optimizer, SGDM_wr)\n",
    "  train_error(epoch, SGDM_modelo, SGDM_wr)\n",
    "  validation(epoch, SGDM_modelo, SGDM_val_wr, SGDM_early_stopper)\n",
    "  test(epoch, SGDM_modelo, SGDM_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GP9Z7gOl36aV"
   },
   "outputs": [],
   "source": [
    "print(\"Training with ADAM\\n***************** Sin entrenamiento *********************\")\n",
    "train_error(0, ADAM_modelo, ADAM_wr)\n",
    "validation(0, ADAM_modelo, ADAM_val_wr, ADAM_early_stopper)\n",
    "test(0, ADAM_modelo, ADAM_wr)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  print(f'***************** Época: {epoch} *********************')\n",
    "  train(epoch, ADAM_modelo, ADAM_optimizer, ADAM_wr)\n",
    "\n",
    "  train_error(epoch, ADAM_modelo, ADAM_wr)\n",
    "  validation(epoch, ADAM_modelo, ADAM_val_wr, ADAM_early_stopper)\n",
    "  test(epoch, ADAM_modelo, ADAM_wr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6s1keMx04GV"
   },
   "source": [
    "## Evaluando los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5SloJ7Jx7qb"
   },
   "outputs": [],
   "source": [
    "if (SGD_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de SGD con un coste de {SGD_early_stopper.val_loss_min}\\nÉpoca número:{SGD_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en SGD, siendo el menor coste: {SGD_early_stopper.val_loss_min}\\n\")\n",
    "\n",
    "if (SGDM_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de SGD con momento con un coste de {SGDM_early_stopper.val_loss_min}\\nÉpoca número:{SGDM_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en SGD con momento, siendo el menor coste: {SGDM_early_stopper.val_loss_min}\\n\")\n",
    "\n",
    "if (ADAM_early_stopper.early_stop):\n",
    "  print(f\"Ha habido una parada temprana en el modelo de ADAM con una precisión de {ADAM_early_stopper.val_loss_min}\\nÉpoca número:{ADAM_early_stopper.stop_iter}\\n\")\n",
    "else:\n",
    "  print(f\"No ha habido early stop en ADAM, siendo el menor coste: {ADAM_early_stopper.val_loss_min}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Álvaro Rubio Segovia\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZZeK3j-8fw-o",
    "L4xg1WX4WLZf",
    "sfT_lpWIcMkz",
    "j05b91APcMko",
    "kDMlcUgKcMke",
    "hi5JRJ6_cOnY",
    "sJrL5YEKcR8p",
    "5cwCTDQ-cR8t",
    "sEUpdFW8cR8w",
    "MRrh2D3HfMEk",
    "TN9qGTSqgy5r",
    "1TkqFkChhyiT"
   ],
   "name": "MINSTClassifier_v4.0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}